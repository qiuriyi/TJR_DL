{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys, random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# save emb to pkl file\n",
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L2_reg=0.001\n",
    "numXcodes=553\n",
    "embDimSize=100\n",
    "hiddenDimSize=200\n",
    "batchSize=100\n",
    "demoSize=3\n",
    "logEps=1e-8\n",
    "windowSize=5\n",
    "verbose=False\n",
    "maxEpochs=1000\n",
    "lr=0.001\n",
    "W_initial=0.01\n",
    "\n",
    "def pickTwo(codes, iVector, jVector):\n",
    "\tfor first in codes:\n",
    "\t\tfor second in codes:\n",
    "\t\t\tif first == second: continue\n",
    "\t\t\tiVector.append(first)\n",
    "\t\t\tjVector.append(second)\n",
    "            \n",
    "def padMatrix(seqs):\n",
    "\tn_samples = len(seqs)\n",
    "\tiVector = []\n",
    "\tjVector = []\n",
    "\tx = np.zeros((n_samples, numXcodes))\n",
    "\tmask = np.zeros((n_samples,))\n",
    "\tfor idx, seq in enumerate(seqs):\n",
    "\t\tif not seq[0] == -1:\n",
    "\t\t\tx[idx][seq] = 1.\n",
    "\t\t\tpickTwo(seq, iVector, jVector)\n",
    "\t\t\tmask[idx] = 1.\n",
    "\treturn x, mask, np.array(iVector), np.array(jVector)\n",
    "\n",
    "def load_obj(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    params = OrderedDict()\n",
    "\n",
    "    params['W_emb'] = tf.get_variable(\"W_emb\", [numXcodes, embDimSize],initializer=tf.random_uniform_initializer(-W_initial,W_initial))\n",
    "    params['b_emb'] = tf.get_variable('b_emb', [embDimSize], initializer=tf.zeros_initializer)\n",
    "\n",
    "    params['W_hidden'] = tf.get_variable(\"W_hidden\", [embDimSize+demoSize, hiddenDimSize],initializer=tf.random_uniform_initializer(-W_initial,W_initial)) #emb matrix needs an extra dimension for the time\n",
    "    params['b_hidden'] = tf.get_variable('b_hidden', [hiddenDimSize], initializer=tf.zeros_initializer)\n",
    "\n",
    "    params['W_output'] = tf.get_variable(\"W_output\", [hiddenDimSize, numXcodes],initializer=tf.random_uniform_initializer(-W_initial,W_initial)) #emb matrix needs an extra dimension for the time\n",
    "    params['b_output'] = tf.get_variable('b_output', [numXcodes], initializer=tf.zeros_initializer)\n",
    "    \n",
    "    tparams = OrderedDict()\n",
    "    for k, v in params.items():\n",
    "        tparams[k] = v\n",
    "    \n",
    "    x = tf.placeholder(tf.float32,name='x',shape=[None,553])\n",
    "    d = tf.placeholder(tf.float32,name='d',shape=[None,3])\n",
    "    mask = tf.placeholder(tf.float32,name='mask',shape=[None,])\n",
    "\n",
    "    emb = tf.maximum(tf.matmul(x, tparams['W_emb'])+tparams['b_emb'],0.0)\n",
    "    if demoSize > 0: emb = tf.concat([emb,d],1)\n",
    "    visit = tf.maximum(tf.matmul(emb,tparams['W_hidden'])+tparams['b_hidden'],0.0)\n",
    "    results = tf.nn.softmax(tf.matmul(visit,tparams['W_output'])+tparams['b_output'])\n",
    "    \n",
    "    mask1 = (mask[:-1] * mask[1:])[:,None]\n",
    "    mask2 = (mask[:-2] * mask[1:-1] * mask[2:])[:,None]\n",
    "    mask3 = (mask[:-3] * mask[1:-2] * mask[2:-1] * mask[3:])[:,None]\n",
    "    mask4 = (mask[:-4] * mask[1:-3] * mask[2:-2] * mask[3:-1] * mask[4:])[:,None]\n",
    "    mask5 = (mask[:-5] * mask[1:-4] * mask[2:-3] * mask[3:-2] * mask[4:-1] * mask[5:])[:,None]\n",
    "    \n",
    "    t = x\n",
    "\n",
    "    forward_results =  results[:-1] * mask1\n",
    "    forward_cross_entropy = -(t[1:] * tf.log(forward_results + logEps) + (1. - t[1:]) * tf.log(1. - forward_results + logEps))\n",
    "\n",
    "    forward_results2 =  results[:-2] * mask2\n",
    "    forward_cross_entropy2 = -(t[2:] * tf.log(forward_results2 + logEps) + (1. - t[2:]) * tf.log(1. - forward_results2 + logEps))\n",
    "\n",
    "    forward_results3 =  results[:-3] * mask3\n",
    "    forward_cross_entropy3 = -(t[3:] * tf.log(forward_results3 + logEps) + (1. - t[3:]) * tf.log(1. - forward_results3 + logEps))\n",
    "\n",
    "    forward_results4 =  results[:-4] * mask4\n",
    "    forward_cross_entropy4 = -(t[4:] * tf.log(forward_results4 + logEps) + (1. - t[4:]) * tf.log(1. - forward_results4 + logEps))\n",
    "\n",
    "    forward_results5 =  results[:-5] * mask5\n",
    "    forward_cross_entropy5 = -(t[5:] * tf.log(forward_results5 + logEps) + (1. - t[5:]) * tf.log(1. - forward_results5 + logEps))\n",
    "\n",
    "    backward_results =  results[1:] * mask1\n",
    "    backward_cross_entropy = -(t[:-1] * tf.log(backward_results + logEps) + (1. - t[:-1]) * tf.log(1. - backward_results + logEps))\n",
    "\n",
    "    backward_results2 =  results[2:] * mask2\n",
    "    backward_cross_entropy2 = -(t[:-2] * tf.log(backward_results2 + logEps) + (1. - t[:-2]) * tf.log(1. - backward_results2 + logEps))\n",
    "\n",
    "    backward_results3 =  results[3:] * mask3\n",
    "    backward_cross_entropy3 = -(t[:-3] * tf.log(backward_results3 + logEps) + (1. - t[:-3]) * tf.log(1. - backward_results3 + logEps))\n",
    "\n",
    "    backward_results4 =  results[4:] * mask4\n",
    "    backward_cross_entropy4 = -(t[:-4] * tf.log(backward_results4 + logEps) + (1. - t[:-4]) * tf.log(1. - backward_results4 + logEps))\n",
    "\n",
    "    backward_results5 =  results[5:] * mask5\n",
    "    backward_cross_entropy5 = -(t[:-5] * tf.log(backward_results5 + logEps) + (1. - t[:-5]) * tf.log(1. - backward_results5 + logEps))\n",
    "\n",
    "    visit_cost1 = (tf.reduce_sum(forward_cross_entropy)+tf.reduce_sum(backward_cross_entropy)) / (tf.reduce_sum(mask1)+logEps)\n",
    "    visit_cost2 = (tf.reduce_sum(forward_cross_entropy2)+tf.reduce_sum(backward_cross_entropy2)) / (tf.reduce_sum(mask2)+logEps)\n",
    "    visit_cost3 = (tf.reduce_sum(forward_cross_entropy3)+tf.reduce_sum(backward_cross_entropy3)) / (tf.reduce_sum(mask3)+logEps)\n",
    "    visit_cost4 = (tf.reduce_sum(forward_cross_entropy4)+tf.reduce_sum(backward_cross_entropy4)) / (tf.reduce_sum(mask4)+logEps)\n",
    "    visit_cost5 = (tf.reduce_sum(forward_cross_entropy5)+tf.reduce_sum(backward_cross_entropy5)) / (tf.reduce_sum(mask5)+logEps)\n",
    "\n",
    "    visit_cost = visit_cost1\n",
    "    if windowSize == 2:\n",
    "        visit_cost = visit_cost1 + visit_cost2\n",
    "    elif windowSize == 3:\n",
    "        visit_cost = visit_cost1 + visit_cost2 + visit_cost3\n",
    "    elif windowSize == 4:\n",
    "        visit_cost = visit_cost1 + visit_cost2 + visit_cost3 + visit_cost4\n",
    "    elif windowSize == 5:\n",
    "        visit_cost = visit_cost1 + visit_cost2 + visit_cost3 + visit_cost4 + visit_cost5\n",
    "        \n",
    "    iVector = tf.placeholder(tf.int32,name='iVector')\n",
    "    jVector = tf.placeholder(tf.int32,name='jVector')\n",
    "    preVec = tf.maximum(tparams['W_emb'],0)\n",
    "\n",
    "\n",
    "    ############## check if tf.reduce_sum is used in a right way\n",
    "    norms = tf.reduce_sum((tf.exp(tf.matmul(preVec, tf.transpose(preVec)))),1)\n",
    "    emb_cost = -tf.log((tf.exp(tf.reduce_sum(tf.multiply(tf.gather(preVec,iVector),tf.gather(preVec,jVector)),axis=1)) / tf.gather(norms,iVector)) + logEps)\n",
    "    \n",
    "    total_cost = visit_cost + tf.reduce_mean(emb_cost) + L2_reg * tf.reduce_sum(tparams['W_emb'] ** 2)\n",
    "\n",
    "    optimizer = tf.train.AdadeltaOptimizer(learning_rate=lr).minimize(total_cost)\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-26 22:37:03.389563 epoch: 0 0 loss: 530.286701821 523.96235245 6.32434937108\n",
      "0.0151689210253 0.000121103\n",
      "2018-06-26 22:38:48.454002 epoch: 0 1 loss: 487.290586223 480.967131367 6.32345485528\n",
      "0.0143143977563 0.000383892\n",
      "2018-06-26 22:40:35.195680 epoch: 0 2 loss: 442.996549603 436.67404634 6.32250326296\n",
      "0.0134716844286 0.00072836\n",
      "2018-06-26 22:42:22.495109 epoch: 0 3 loss: 388.610197616 382.288914278 6.32128333861\n",
      "0.0126730158124 0.00116998\n",
      "2018-06-26 22:44:07.601987 epoch: 0 4 loss: 337.826403451 331.506045554 6.32035789639\n",
      "0.0118926951446 0.0017404\n",
      "2018-06-26 22:45:54.910643 epoch: 0 5 loss: 290.487043667 284.168113416 6.3189302509\n",
      "0.0111411147198 0.00241998\n",
      "2018-06-26 22:47:39.979739 epoch: 0 6 loss: 254.934794488 248.617081101 6.3177133873\n",
      "0.0103520945656 0.00306416\n",
      "2018-06-26 22:49:27.053905 epoch: 0 7 loss: 236.393728596 230.077207465 6.31652113099\n",
      "0.00952687066081 0.00355428\n",
      "2018-06-26 22:51:14.059510 epoch: 0 8 loss: 223.670174377 217.354607187 6.31556718966\n",
      "0.0087429395609 0.00404334\n",
      "2018-06-26 22:53:00.976206 epoch: 0 9 loss: 209.65779203 203.343539006 6.31425302416\n",
      "0.007925039798 0.00451337\n",
      "2018-06-26 22:54:48.067676 epoch: 0 10 loss: 200.967615649 194.654193342 6.31342230715\n",
      "0.00705692135179 0.00486156\n",
      "2018-06-26 22:56:34.386361 epoch: 0 11 loss: 195.527491405 189.215073354 6.31241805076\n",
      "0.00614959341872 0.00503252\n",
      "2018-06-26 22:58:21.798923 epoch: 0 12 loss: 193.001932461 186.690182979 6.31174948152\n",
      "0.00522351822775 0.00512047\n",
      "2018-06-26 23:00:09.301061 epoch: 0 13 loss: 191.406983867 185.096037431 6.31094643596\n",
      "0.00436110159764 0.00520922\n",
      "2018-06-26 23:01:53.697080 epoch: 0 14 loss: 191.743025026 185.43260119 6.31042383648\n",
      "0.00346191051164 0.0052903\n",
      "2018-06-26 23:03:42.235361 epoch: 0 15 loss: 189.709275187 183.399747444 6.30952774323\n",
      "0.00256183057649 0.00535545\n",
      "2018-06-26 23:05:27.693528 epoch: 0 16 loss: 187.99100572 181.682106759 6.30889896126\n",
      "0.0016377300787 0.00541968\n",
      "2018-06-26 23:07:14.168759 epoch: 0 17 loss: 187.767837593 181.459612474 6.30822511882\n",
      "0.000722975850843 0.0054693\n",
      "2018-06-26 23:09:00.985216 epoch: 0 18 loss: 185.910168019 179.602728472 6.30743954704\n",
      "-0.000194453711805 0.00553037\n",
      "2018-06-26 23:10:48.695641 epoch: 0 19 loss: 184.781030107 178.47415471 6.30687539638\n",
      "-0.0011306645265 0.00558524\n",
      "2018-06-26 23:12:36.141385 epoch: 0 20 loss: 185.229326107 178.923049649 6.30627645806\n",
      "-0.00203534698916 0.00562664\n",
      "2018-06-26 23:14:23.499375 epoch: 0 21 loss: 183.552888935 177.247241723 6.30564721245\n",
      "-0.00294327909387 0.00567902\n",
      "2018-06-26 23:16:11.108803 epoch: 0 22 loss: 182.911378287 176.606373107 6.30500518039\n",
      "-0.00389449202065 0.00572301\n",
      "2018-06-26 23:17:58.684684 epoch: 0 23 loss: 183.208587423 176.904577395 6.30401002887\n",
      "-0.0047936333805 0.00576657\n",
      "2018-06-26 23:19:48.184216 epoch: 0 24 loss: 182.563171538 176.259732869 6.30343866949\n",
      "-0.00566542213438 0.00581792\n",
      "2018-06-26 23:21:36.777024 epoch: 0 25 loss: 180.687280815 174.384431063 6.30284975196\n",
      "-0.00657452497212 0.00587044\n",
      "2018-06-26 23:23:25.821997 epoch: 0 26 loss: 180.878779902 174.576760836 6.30201906642\n",
      "-0.00743247778867 0.00593444\n",
      "2018-06-26 23:25:12.708546 epoch: 0 27 loss: 181.599579852 175.298049188 6.30153066394\n",
      "-0.00833509917781 0.00598435\n",
      "2018-06-26 23:27:01.382622 epoch: 0 28 loss: 181.404795945 175.1039886 6.30080734501\n",
      "-0.0092009620437 0.00604453\n",
      "2018-06-26 23:28:48.798256 epoch: 0 29 loss: 181.416564026 175.116468392 6.30009563352\n",
      "-0.0100929961075 0.0061072\n",
      "2018-06-26 23:30:36.165526 epoch: 0 30 loss: 180.249173147 173.949766715 6.2994064314\n",
      "-0.010980076138 0.00617684\n",
      "2018-06-26 23:32:23.465923 epoch: 0 31 loss: 180.75628254 174.457506603 6.29877593663\n",
      "-0.0118549579679 0.00624134\n",
      "2018-06-26 23:34:10.903693 epoch: 0 32 loss: 180.734849709 174.436736678 6.29811303017\n",
      "-0.0127399954163 0.00630285\n",
      "2018-06-26 23:35:57.840921 epoch: 0 33 loss: 181.427932703 175.130359201 6.29757350146\n",
      "-0.0135824665677 0.00636325\n",
      "2018-06-26 23:37:43.464018 epoch: 0 34 loss: 180.775682848 174.47895418 6.29672866782\n",
      "-0.014435142532 0.00644304\n",
      "2018-06-26 23:39:29.942763 epoch: 0 35 loss: 180.390403742 174.094361068 6.29604267418\n",
      "-0.0152587386219 0.00651499\n",
      "2018-06-26 23:41:17.679209 epoch: 0 36 loss: 180.823322397 174.527852408 6.29546998941\n",
      "-0.0161269088507 0.00658401\n",
      "2018-06-26 23:43:04.688905 epoch: 0 37 loss: 180.548470716 174.253743245 6.29472747084\n",
      "-0.0169856496772 0.00666333\n",
      "2018-06-26 23:44:50.734146 epoch: 0 38 loss: 180.733970802 174.439724026 6.29424677692\n",
      "-0.0178313264958 0.0067431\n",
      "2018-06-26 23:46:38.867089 epoch: 0 39 loss: 180.414739182 174.12115572 6.29358346219\n",
      "-0.0186896456593 0.00682526\n",
      "2018-06-26 23:48:26.817639 epoch: 0 40 loss: 179.922444193 173.629626039 6.29281815402\n",
      "-0.0195540745638 0.00691273\n",
      "2018-06-26 23:50:13.416587 epoch: 0 41 loss: 180.963657649 174.671712138 6.29194551046\n",
      "-0.0203867422611 0.00700117\n",
      "2018-06-26 23:52:01.248838 epoch: 0 42 loss: nan 173.527697651 nan\n",
      "-0.0212458335218 0.0070891\n",
      "2018-06-26 23:53:48.266666 epoch: 0 43 loss: 179.482191095 173.191396052 6.29079504266\n",
      "-0.0220803408511 0.00718133\n",
      "2018-06-26 23:55:35.260029 epoch: 0 44 loss: 180.254234163 173.964045794 6.29018836872\n",
      "-0.0229205254388 0.00727127\n",
      "2018-06-26 23:57:23.012771 epoch: 0 45 loss: 180.438566641 174.149071874 6.28949476726\n",
      "-0.0237392073405 0.0073671\n",
      "2018-06-26 23:59:10.577119 epoch: 0 46 loss: 180.317413836 174.028559478 6.28885435843\n",
      "-0.0245314191097 0.00746216\n",
      "2018-06-27 00:00:57.955125 epoch: 0 47 loss: 178.793471455 172.505335185 6.28813626994\n",
      "-0.0253229396875 0.00756698\n",
      "2018-06-27 00:02:45.259012 epoch: 0 48 loss: 179.386554799 173.099140506 6.28741429236\n",
      "-0.0261282258599 0.00767462\n",
      "2018-06-27 00:04:32.722968 epoch: 0 49 loss: 179.108029467 172.821212767 6.28681670042\n",
      "-0.0269413459883 0.00778174\n",
      "2018-06-27 00:06:18.740111 epoch: 0 50 loss: 179.774110888 173.487970447 6.28614044029\n",
      "-0.0277553223966 0.00789189\n",
      "2018-06-27 00:08:04.795731 epoch: 0 51 loss: 179.346370274 173.060952769 6.28541750534\n",
      "-0.0285578579784 0.00800785\n",
      "2018-06-27 00:09:51.158600 epoch: 0 52 loss: 178.473784309 172.189258524 6.28452578506\n",
      "-0.0293864093619 0.00812557\n",
      "2018-06-27 00:11:38.101439 epoch: 1 0 loss: 179.403936055 173.120030399 6.28390565625\n",
      "-0.0302429282918 0.00823906\n",
      "2018-06-27 00:13:25.207068 epoch: 1 1 loss: 177.825169406 171.541872241 6.28329716544\n",
      "-0.031017345563 0.00836249\n",
      "2018-06-27 00:15:11.087316 epoch: 1 2 loss: 179.975619201 173.692849654 6.28276954717\n",
      "-0.0318316585641 0.00847598\n",
      "2018-06-27 00:16:57.878013 epoch: 1 3 loss: 179.171331455 172.889482824 6.28184863066\n",
      "-0.0326186412325 0.00860351\n",
      "2018-06-27 00:18:45.094096 epoch: 1 4 loss: 180.477777181 174.19632181 6.28145537139\n",
      "-0.0334076487771 0.00872729\n",
      "2018-06-27 00:20:31.948015 epoch: 1 5 loss: 179.134068694 172.853570197 6.28049849673\n",
      "-0.034195287123 0.0088514\n",
      "2018-06-27 00:22:18.098816 epoch: 1 6 loss: 178.315258282 172.035450797 6.27980748456\n",
      "-0.0349931060564 0.00897833\n",
      "2018-06-27 00:24:03.278844 epoch: 1 7 loss: 179.617159065 173.337986902 6.2791721621\n",
      "-0.0357820753375 0.0091073\n",
      "2018-06-27 00:25:50.111378 epoch: 1 8 loss: 180.522959024 174.244314987 6.27864403726\n",
      "-0.0365356287837 0.00924145\n",
      "2018-06-27 00:27:38.330716 epoch: 1 9 loss: 179.086756915 172.809120287 6.27763662866\n",
      "-0.0372927205083 0.00937909\n",
      "2018-06-27 00:29:24.948016 epoch: 1 10 loss: 178.509773713 172.232492933 6.27728077956\n",
      "-0.0380516977561 0.00951536\n",
      "2018-06-27 00:31:12.176962 epoch: 1 11 loss: 177.627722119 171.351337051 6.2763850684\n",
      "-0.0388104782194 0.00965689\n",
      "2018-06-27 00:32:58.526473 epoch: 1 12 loss: 178.446839223 172.171012513 6.27582670946\n",
      "-0.0395719069227 0.00979135\n",
      "2018-06-27 00:34:45.056547 epoch: 1 13 loss: 178.796819363 172.521754012 6.27506535104\n",
      "-0.0402824440377 0.00993879\n",
      "2018-06-27 00:36:30.746549 epoch: 1 14 loss: 180.724376226 174.449775796 6.27460042994\n",
      "-0.0410150806952 0.0100848\n",
      "2018-06-27 00:38:16.126996 epoch: 1 15 loss: 180.026646966 173.752877453 6.27376951256\n",
      "-0.0417399480702 0.0102336\n",
      "2018-06-27 00:40:01.801866 epoch: 1 16 loss: 179.232422856 172.959386728 6.27303612783\n",
      "-0.0424882154442 0.010388\n",
      "2018-06-27 00:41:49.341239 epoch: 1 17 loss: 180.197902858 173.925454527 6.27244833065\n",
      "-0.043226555926 0.0105378\n",
      "2018-06-27 00:43:36.903469 epoch: 1 18 loss: 179.237188401 172.965575743 6.27161265864\n",
      "-0.0439815037674 0.0106956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 00:45:24.150279 epoch: 1 19 loss: 178.616660291 172.345628409 6.27103188153\n",
      "-0.0447351484281 0.0108469\n",
      "2018-06-27 00:47:11.541031 epoch: 1 20 loss: 179.77646299 173.506012182 6.27045080858\n",
      "-0.0454631887491 0.0109924\n",
      "2018-06-27 00:48:58.569617 epoch: 1 21 loss: 178.4532952 172.183517256 6.26977794363\n",
      "-0.0461985100158 0.0111526\n",
      "2018-06-27 00:50:44.311387 epoch: 1 22 loss: 178.359528515 172.090458852 6.26906966211\n",
      "-0.0469629137646 0.0113028\n",
      "2018-06-27 00:52:30.906574 epoch: 1 23 loss: 179.03357545 172.765491678 6.26808377145\n",
      "-0.0476849004394 0.0114557\n",
      "2018-06-27 00:54:18.574985 epoch: 1 24 loss: 178.680587599 172.41305122 6.26753637822\n",
      "-0.0483894184218 0.0116152\n",
      "2018-06-27 00:56:06.409609 epoch: 1 25 loss: 177.107310013 170.840501243 6.26680877009\n",
      "-0.0491296231529 0.0117782\n",
      "2018-06-27 00:57:53.005874 epoch: 1 26 loss: 177.594465565 171.32845903 6.26600653452\n",
      "-0.0498199096306 0.0119462\n",
      "2018-06-27 00:59:40.256317 epoch: 1 27 loss: 178.463727359 172.198202437 6.26552492227\n",
      "-0.050547791048 0.0121037\n",
      "2018-06-27 01:01:27.662598 epoch: 1 28 loss: 178.452393115 172.187617346 6.26477576818\n",
      "-0.0512435807867 0.0122724\n",
      "2018-06-27 01:03:14.196319 epoch: 1 29 loss: 178.661203866 172.397130442 6.26407342397\n",
      "-0.0519554641629 0.0124401\n",
      "2018-06-27 01:05:00.524291 epoch: 1 30 loss: 177.612791083 171.349477455 6.26331362778\n",
      "-0.0526756174259 0.0126107\n",
      "2018-06-27 01:06:47.198721 epoch: 1 31 loss: 178.293557004 172.030848762 6.26270824184\n",
      "-0.0533939904141 0.0127718\n",
      "2018-06-27 01:08:34.332071 epoch: 1 32 loss: 178.299244453 172.037177801 6.26206665208\n",
      "-0.0541173690444 0.0129316\n",
      "2018-06-27 01:10:21.851641 epoch: 1 33 loss: 179.181359966 172.919863779 6.26149618682\n",
      "-0.0547981528005 0.0130923\n",
      "2018-06-27 01:12:06.359367 epoch: 1 34 loss: 178.658842207 172.398259171 6.26058303646\n",
      "-0.0554760140866 0.0132626\n",
      "2018-06-27 01:13:51.910511 epoch: 1 35 loss: 178.347793236 172.0878164 6.25997683628\n",
      "-0.0561415781908 0.0134263\n",
      "2018-06-27 01:15:38.372374 epoch: 1 36 loss: 178.933716634 172.674344033 6.25937260123\n",
      "-0.0568627885981 0.0135871\n",
      "2018-06-27 01:17:24.328548 epoch: 1 37 loss: 178.686323823 172.427695638 6.25862818555\n",
      "-0.0575834627762 0.013756\n",
      "2018-06-27 01:19:09.951357 epoch: 1 38 loss: 178.916061047 172.657913977 6.25814707069\n",
      "-0.0582793260043 0.0139243\n",
      "2018-06-27 01:20:56.847804 epoch: 1 39 loss: 178.655332461 172.397788013 6.25754444875\n",
      "-0.0589819284967 0.0140949\n",
      "2018-06-27 01:22:43.172564 epoch: 1 40 loss: 178.27616196 172.019279486 6.25688247416\n",
      "-0.0596948477643 0.0142722\n",
      "2018-06-27 01:24:28.785117 epoch: 1 41 loss: 179.296904927 173.041022878 6.25588204851\n",
      "-0.0603766932505 0.014448\n",
      "2018-06-27 01:26:15.354751 epoch: 1 42 loss: nan 171.921060366 nan\n",
      "-0.0610838943156 0.0146213\n",
      "2018-06-27 01:28:01.300183 epoch: 1 43 loss: 177.877928951 171.623221136 6.25470781553\n",
      "-0.0617825222613 0.0147955\n",
      "2018-06-27 01:29:46.829669 epoch: 1 44 loss: 178.721023967 172.466900885 6.25412308193\n",
      "-0.0624819846925 0.0149703\n",
      "2018-06-27 01:31:34.521094 epoch: 1 45 loss: 178.9353444 172.681880764 6.25346363573\n",
      "-0.0631495617458 0.0151443\n",
      "2018-06-27 01:33:20.070271 epoch: 1 46 loss: 178.790378851 172.537492667 6.25288618425\n",
      "-0.0638084822295 0.0153184\n",
      "2018-06-27 01:35:05.452692 epoch: 1 47 loss: 177.257049744 171.005030347 6.25201939676\n",
      "-0.0644449738574 0.0154997\n",
      "2018-06-27 01:36:50.823957 epoch: 1 48 loss: 177.904185982 171.65276766 6.25141832135\n",
      "-0.0650949415649 0.0156769\n",
      "2018-06-27 01:38:37.848188 epoch: 1 49 loss: 177.635423035 171.384605471 6.2508175637\n",
      "-0.0657428467284 0.0158561\n",
      "2018-06-27 01:40:24.025330 epoch: 1 50 loss: 178.332995883 172.0828391 6.25015678299\n",
      "-0.0663989161463 0.0160374\n",
      "2018-06-27 01:42:08.747887 epoch: 1 51 loss: 177.944809199 171.695308642 6.24950055693\n",
      "-0.0670423752747 0.0162186\n",
      "2018-06-27 01:43:55.594214 epoch: 1 52 loss: 177.115144696 170.866571832 6.24857286456\n",
      "-0.0677135380477 0.0164025\n",
      "2018-06-27 01:45:42.565309 epoch: 2 0 loss: 178.051776594 171.80377454 6.2480020539\n",
      "-0.0684028654884 0.016578\n",
      "2018-06-27 01:47:28.486290 epoch: 2 1 loss: 176.502787363 170.255363222 6.24742414103\n",
      "-0.0690339241448 0.0167622\n",
      "2018-06-27 01:49:14.214356 epoch: 2 2 loss: 178.657204736 172.410238228 6.24696650737\n",
      "-0.0696761484577 0.0169392\n",
      "2018-06-27 01:51:01.185954 epoch: 2 3 loss: 177.848556262 171.602503367 6.24605289451\n",
      "-0.070314766976 0.0171248\n",
      "2018-06-27 01:52:45.962690 epoch: 2 4 loss: 179.164942928 172.919150241 6.24579268671\n",
      "-0.0709602375783 0.0173068\n",
      "2018-06-27 01:54:33.697739 epoch: 2 5 loss: 177.877553953 171.632800233 6.24475371988\n",
      "-0.0716036503221 0.0174827\n",
      "2018-06-27 01:56:18.081482 epoch: 2 6 loss: 177.057889003 170.81386029 6.24402871268\n",
      "-0.072259856776 0.0176626\n",
      "2018-06-27 01:58:03.887178 epoch: 2 7 loss: 178.346998642 172.103570877 6.24342776517\n",
      "-0.0729071419919 0.017841\n",
      "2018-06-27 01:59:50.917986 epoch: 2 8 loss: 179.245373663 173.002378088 6.24299557541\n",
      "-0.0735209183511 0.0180211\n",
      "2018-06-27 02:01:38.318913 epoch: 2 9 loss: 177.869704111 171.627747631 6.24195647953\n",
      "-0.0741455135743 0.0182056\n",
      "2018-06-27 02:03:23.960883 epoch: 2 10 loss: 177.303145621 171.061414887 6.24173073454\n",
      "-0.0747633805795 0.0183834\n",
      "2018-06-27 02:05:12.828386 epoch: 2 11 loss: 176.420955536 170.180095275 6.24086026134\n",
      "-0.0753865415838 0.0185616\n",
      "2018-06-27 02:07:00.893036 epoch: 2 12 loss: 177.223145493 170.982829307 6.24031618633\n",
      "-0.0760237825803 0.0187347\n",
      "2018-06-27 02:08:47.493938 epoch: 2 13 loss: 177.592537904 171.352901869 6.23963603428\n",
      "-0.076622824327 0.0189161\n",
      "2018-06-27 02:10:33.256476 epoch: 2 14 loss: 179.547143253 173.307865046 6.23927820725\n",
      "-0.0772274824463 0.0190999\n",
      "2018-06-27 02:12:19.979190 epoch: 2 15 loss: 178.842652016 172.604125989 6.23852602756\n",
      "-0.0778280506865 0.0192804\n",
      "2018-06-27 02:14:04.882320 epoch: 2 16 loss: 178.050068108 171.81235136 6.23771674845\n",
      "-0.0784441598651 0.0194674\n",
      "2018-06-27 02:15:50.624628 epoch: 2 17 loss: 179.0495219 172.812260536 6.23726136455\n",
      "-0.0790500737775 0.01965\n",
      "2018-06-27 02:17:37.480541 epoch: 2 18 loss: 178.10410353 171.867622491 6.23648103935\n",
      "-0.0796853433227 0.0198347\n",
      "2018-06-27 02:19:23.931483 epoch: 2 19 loss: 177.497169876 171.261215236 6.23595463971\n",
      "-0.0803136122671 0.0200139\n",
      "2018-06-27 02:21:09.808826 epoch: 2 20 loss: 178.676634151 172.441199719 6.23543443152\n",
      "-0.0809236550135 0.0201878\n",
      "2018-06-27 02:22:57.047853 epoch: 2 21 loss: 177.321344641 171.086549963 6.23479467859\n",
      "-0.0815358238397 0.0203729\n",
      "2018-06-27 02:24:43.425575 epoch: 2 22 loss: 177.260115737 171.02606972 6.23404601674\n",
      "-0.0821718200992 0.0205477\n",
      "2018-06-27 02:26:29.999852 epoch: 2 23 loss: 177.949949746 171.716759378 6.23319036839\n",
      "-0.0827570415392 0.0207239\n",
      "2018-06-27 02:28:17.529679 epoch: 2 24 loss: 177.61499573 171.382241271 6.23275445852\n",
      "-0.0833338237561 0.0209028\n",
      "2018-06-27 02:30:05.399046 epoch: 2 25 loss: 176.071761982 169.83981003 6.2319519511\n",
      "-0.0839287904787 0.0210863\n",
      "2018-06-27 02:31:51.497970 epoch: 2 26 loss: 176.565363383 170.334083527 6.23127985565\n",
      "-0.0844947196606 0.0212705\n",
      "2018-06-27 02:33:36.618026 epoch: 2 27 loss: 177.417952938 171.187112592 6.2308403468\n",
      "-0.0850850090851 0.0214493\n",
      "2018-06-27 02:35:24.599171 epoch: 2 28 loss: 177.417542911 171.187397228 6.23014568288\n",
      "-0.0856501615195 0.0216331\n",
      "2018-06-27 02:37:10.001898 epoch: 2 29 loss: 177.635387187 171.405843969 6.22954321793\n",
      "-0.0862427936953 0.0218162\n",
      "2018-06-27 02:38:54.302486 epoch: 2 30 loss: 176.635697993 170.406863424 6.22883456973\n",
      "-0.086821279945 0.0219963\n",
      "2018-06-27 02:40:40.014146 epoch: 2 31 loss: 177.304066792 171.075759453 6.22830733932\n",
      "-0.0873949545248 0.0221725\n",
      "2018-06-27 02:42:27.293169 epoch: 2 32 loss: 177.317235945 171.089440787 6.22779515873\n",
      "-0.0879715773408 0.0223473\n",
      "2018-06-27 02:44:14.246609 epoch: 2 33 loss: 178.203885938 171.976658624 6.22722731396\n",
      "-0.0885284012901 0.0225209\n",
      "2018-06-27 02:45:59.820917 epoch: 2 34 loss: 177.71521981 171.488898509 6.22632130065\n",
      "-0.0890777084717 0.0227011\n",
      "2018-06-27 02:47:45.087608 epoch: 2 35 loss: 177.413972195 171.188068167 6.22590402831\n",
      "-0.0896126191279 0.0228749\n",
      "2018-06-27 02:49:31.005741 epoch: 2 36 loss: 177.991207808 171.765883141 6.22532466677\n",
      "-0.0901898916974 0.0230495\n",
      "2018-06-27 02:51:16.104783 epoch: 2 37 loss: 177.777618482 171.552915761 6.22470272122\n",
      "-0.0907707208567 0.0232228\n",
      "2018-06-27 02:53:00.631285 epoch: 2 38 loss: 177.994796166 171.770566833 6.22422933363\n",
      "-0.0913240008604 0.0233992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 02:54:46.458431 epoch: 2 39 loss: 177.755008578 171.531210052 6.22379852646\n",
      "-0.0918976092241 0.0235754\n",
      "2018-06-27 02:56:33.507790 epoch: 2 40 loss: 177.394941415 171.17162394 6.22331747462\n",
      "-0.0924687288354 0.0237615\n",
      "2018-06-27 02:58:20.148646 epoch: 2 41 loss: 178.417053507 172.194761687 6.22229182021\n",
      "-0.0930101866218 0.0239429\n",
      "2018-06-27 03:00:07.404580 epoch: 2 42 loss: nan 171.084597615 nan\n",
      "-0.0935836481561 0.0241223\n",
      "2018-06-27 03:01:52.796821 epoch: 2 43 loss: 177.022388722 170.801191121 6.221197601\n",
      "-0.0941403693531 0.024298\n",
      "2018-06-27 03:03:37.472635 epoch: 2 44 loss: 177.874299448 171.653602246 6.22069720173\n",
      "-0.0946938931573 0.0244755\n",
      "2018-06-27 03:05:22.722780 epoch: 2 45 loss: 178.103218153 171.883062036 6.22015611748\n",
      "-0.0952256500409 0.0246521\n",
      "2018-06-27 03:07:07.967946 epoch: 2 46 loss: 177.940356032 171.720659538 6.21969649371\n",
      "-0.095738517965 0.0248299\n",
      "2018-06-27 03:08:54.493950 epoch: 2 47 loss: 176.411800644 170.193089213 6.21871143137\n",
      "-0.09624423575 0.025012\n",
      "2018-06-27 03:10:40.450519 epoch: 2 48 loss: 177.102732722 170.884395911 6.2183368115\n",
      "-0.0967652648094 0.0251883\n",
      "2018-06-27 03:12:28.160392 epoch: 2 49 loss: 176.822174122 170.604374184 6.21779993774\n",
      "-0.0972883267048 0.0253683\n",
      "2018-06-27 03:14:13.934596 epoch: 2 50 loss: 177.511518009 171.294331909 6.21718610074\n",
      "-0.0978085992862 0.025547\n",
      "2018-06-27 03:16:00.629329 epoch: 2 51 loss: 177.162120319 170.945435173 6.21668514647\n",
      "-0.0983190517784 0.0257266\n",
      "2018-06-27 03:17:45.186309 epoch: 2 52 loss: 176.349594073 170.133800551 6.21579352167\n",
      "-0.0988382643454 0.0259044\n",
      "2018-06-27 03:19:32.457011 epoch: 3 0 loss: 177.281023207 171.065700441 6.21532276562\n",
      "-0.0993768656451 0.0260805\n",
      "2018-06-27 03:21:16.587255 epoch: 3 1 loss: 175.73711468 169.52226552 6.21484916016\n",
      "-0.0998663894381 0.0262601\n",
      "2018-06-27 03:23:02.693085 epoch: 3 2 loss: 177.883403839 171.668914571 6.21448926803\n",
      "-0.100364152839 0.0264376\n",
      "2018-06-27 03:24:48.132133 epoch: 3 3 loss: 177.082797282 170.869146841 6.21365044046\n",
      "-0.100860416314 0.0266203\n",
      "2018-06-27 03:26:33.558060 epoch: 3 4 loss: 178.394414553 172.180842831 6.21357172137\n",
      "-0.101348707407 0.0268021\n",
      "2018-06-27 03:28:20.906681 epoch: 3 5 loss: 177.145434291 170.932919282 6.2125150094\n",
      "-0.101837138089 0.0269769\n",
      "2018-06-27 03:30:05.782563 epoch: 3 6 loss: 176.315737868 170.103954377 6.21178349068\n",
      "-0.102337069537 0.02715\n",
      "2018-06-27 03:31:52.282734 epoch: 3 7 loss: 177.59007476 171.378811411 6.21126334974\n",
      "-0.102834249186 0.0273255\n",
      "2018-06-27 03:33:37.728731 epoch: 3 8 loss: 178.490816903 172.27983091 6.21098599291\n",
      "-0.10330182627 0.0275067\n",
      "2018-06-27 03:35:24.548575 epoch: 3 9 loss: 177.131200086 170.921226299 6.20997378612\n",
      "-0.103776324961 0.0276855\n",
      "2018-06-27 03:37:11.817582 epoch: 3 10 loss: 176.586668902 170.376767393 6.20990150823\n",
      "-0.104252744926 0.0278577\n",
      "2018-06-27 03:39:04.072165 epoch: 3 11 loss: 175.700925005 169.491778777 6.20914622814\n",
      "-0.104744671557 0.0280331\n",
      "2018-06-27 03:40:50.221198 epoch: 3 12 loss: 176.489539467 170.280919731 6.20861973594\n",
      "-0.10522571627 0.028205\n",
      "2018-06-27 03:42:35.228201 epoch: 3 13 loss: 176.863087411 170.655021593 6.20806581761\n",
      "-0.105675312549 0.0283833\n",
      "2018-06-27 03:44:18.583232 epoch: 3 14 loss: 178.834201194 172.626342967 6.20785822718\n",
      "-0.106132253537 0.0285585\n",
      "2018-06-27 03:46:05.316819 epoch: 3 15 loss: 178.111916614 171.904708348 6.20720826561\n",
      "-0.106568541857 0.0287382\n",
      "2018-06-27 03:47:50.304814 epoch: 3 16 loss: 177.323683799 171.117328245 6.20635555454\n",
      "-0.107024172165 0.028922\n",
      "2018-06-27 03:49:36.610972 epoch: 3 17 loss: 178.328153565 172.122084396 6.2060691688\n",
      "-0.107488281256 0.0291014\n",
      "2018-06-27 03:51:22.880734 epoch: 3 18 loss: 177.404666675 171.19925056 6.20541611523\n",
      "-0.107960535073 0.0292821\n",
      "2018-06-27 03:53:08.094292 epoch: 3 19 loss: 176.800287341 170.595331693 6.20495564795\n",
      "-0.108428332446 0.0294567\n",
      "2018-06-27 03:54:56.531143 epoch: 3 20 loss: 177.97525524 171.770726151 6.20452908978\n",
      "-0.108862738628 0.0296247\n",
      "2018-06-27 03:56:43.213169 epoch: 3 21 loss: 176.621281281 170.417324797 6.20395648445\n",
      "-0.109317421926 0.029804\n",
      "2018-06-27 03:58:30.040030 epoch: 3 22 loss: 176.557335221 170.354140979 6.20319424268\n",
      "-0.109793208444 0.0299705\n",
      "2018-06-27 04:00:17.010031 epoch: 3 23 loss: 177.258060071 171.055575248 6.20248482357\n",
      "-0.110231995223 0.0301419\n",
      "2018-06-27 04:02:02.035487 epoch: 3 24 loss: 176.923798462 170.721590654 6.20220780739\n",
      "-0.110667167836 0.030317\n",
      "2018-06-27 04:03:48.123093 epoch: 3 25 loss: 175.388082131 169.186714098 6.20136803287\n",
      "-0.11111270436 0.0304904\n",
      "2018-06-27 04:05:33.054793 epoch: 3 26 loss: 175.896321523 169.695458591 6.20086293179\n",
      "-0.11153620726 0.0306712\n",
      "2018-06-27 04:07:19.808022 epoch: 3 27 loss: 176.723771446 170.523308732 6.20046271443\n",
      "-0.111980782406 0.0308457\n",
      "2018-06-27 04:09:06.664188 epoch: 3 28 loss: 176.724456083 170.52460508 6.19985100287\n",
      "-0.112407248619 0.0310236\n",
      "2018-06-27 04:10:52.859250 epoch: 3 29 loss: 176.951671353 170.752279129 6.19939222354\n",
      "-0.112836316162 0.0312014\n",
      "2018-06-27 04:12:39.898839 epoch: 3 30 loss: 175.981334178 169.782584812 6.1987493663\n",
      "-0.113255231611 0.0313753\n",
      "2018-06-27 04:14:25.640259 epoch: 3 31 loss: 176.638891676 170.440573507 6.19831816868\n",
      "-0.113675340079 0.0315465\n",
      "2018-06-27 04:16:12.293776 epoch: 3 32 loss: 176.660339422 170.462389354 6.19795006803\n",
      "-0.114108554868 0.031714\n",
      "2018-06-27 04:17:57.882518 epoch: 3 33 loss: 177.537521908 171.340123417 6.19739849092\n",
      "-0.114513640283 0.0318842\n",
      "2018-06-27 04:19:42.511664 epoch: 3 34 loss: 177.056946089 170.86042359 6.19652249829\n",
      "-0.114922072926 0.0320592\n",
      "2018-06-27 04:21:28.721693 epoch: 3 35 loss: 176.762907402 170.566610789 6.19629661264\n",
      "-0.115315571135 0.0322272\n",
      "2018-06-27 04:23:14.362645 epoch: 3 36 loss: 177.33494565 171.139176881 6.19576876918\n",
      "-0.115748471288 0.0323948\n",
      "2018-06-27 04:25:00.061785 epoch: 3 37 loss: 177.145078389 170.949777888 6.19530050102\n",
      "-0.11617509589 0.0325644\n",
      "2018-06-27 04:26:44.723452 epoch: 3 38 loss: 177.346000446 171.151191657 6.19480878989\n",
      "-0.116588325069 0.0327332\n",
      "2018-06-27 04:28:31.641159 epoch: 3 39 loss: 177.114714969 170.920126089 6.19458888038\n",
      "-0.117000622017 0.0329063\n",
      "2018-06-27 04:30:16.484212 epoch: 3 40 loss: 176.763216 170.568934538 6.19428146235\n",
      "-0.117422245259 0.0330883\n",
      "2018-06-27 04:32:04.140453 epoch: 3 41 loss: 177.793279653 171.600033863 6.19324579012\n",
      "-0.117819522189 0.0332634\n",
      "2018-06-27 04:33:52.211618 epoch: 3 42 loss: nan 170.487623279 nan\n",
      "-0.118228952035 0.0334338\n",
      "2018-06-27 04:35:38.826966 epoch: 3 43 loss: 176.397483556 170.205243692 6.19223986326\n",
      "-0.118634297058 0.0336032\n",
      "2018-06-27 04:37:26.231898 epoch: 3 44 loss: 177.247342688 171.055507278 6.19183540986\n",
      "-0.119038331594 0.0337731\n",
      "2018-06-27 04:39:12.620981 epoch: 3 45 loss: 177.474228407 171.282791763 6.19143664432\n",
      "-0.119415756237 0.0339439\n",
      "2018-06-27 04:41:01.328098 epoch: 3 46 loss: 177.299731098 171.108670681 6.191060417\n",
      "-0.119774896382 0.0341185\n",
      "2018-06-27 04:42:46.129313 epoch: 3 47 loss: 175.780398569 169.590409573 6.18998899683\n",
      "-0.120139696651 0.0342939\n",
      "2018-06-27 04:44:32.173691 epoch: 3 48 loss: 176.498577442 170.308742214 6.18983522803\n",
      "-0.120517137441 0.034462\n",
      "2018-06-27 04:46:18.847028 epoch: 3 49 loss: 176.210612533 170.021254571 6.18935796179\n",
      "-0.120892424091 0.0346363\n",
      "2018-06-27 04:48:03.832470 epoch: 3 50 loss: 176.887879414 170.699056116 6.18882329871\n",
      "-0.121278514322 0.0348102\n",
      "2018-06-27 04:49:48.149763 epoch: 3 51 loss: 176.560745357 170.372292304 6.188453053\n",
      "-0.121651309872 0.0349824\n",
      "2018-06-27 04:51:34.543629 epoch: 3 52 loss: 175.759439925 169.571849276 6.18759064983\n",
      "-0.122039516217 0.0351518\n",
      "2018-06-27 04:53:19.555778 epoch: 4 0 loss: 176.675388835 170.488165712 6.18722312309\n",
      "-0.122423486413 0.0353236\n",
      "2018-06-27 04:55:07.057627 epoch: 4 1 loss: 175.14028633 168.953445297 6.18684103223\n",
      "-0.122751761685 0.0354966\n",
      "2018-06-27 04:56:54.004766 epoch: 4 2 loss: 177.275402454 171.088840656 6.186561798\n",
      "-0.123102025888 0.035667\n",
      "2018-06-27 04:58:40.058601 epoch: 4 3 loss: 176.478688726 170.292867026 6.18582169929\n",
      "-0.123443750739 0.0358411\n",
      "2018-06-27 05:00:26.249604 epoch: 4 4 loss: 177.785143077 171.5992454 6.18589767665\n",
      "-0.123791528831 0.0360173\n",
      "2018-06-27 05:02:12.724419 epoch: 4 5 loss: 176.56682753 170.382010865 6.18481666444\n",
      "-0.12412829598 0.036184\n",
      "2018-06-27 05:03:59.123360 epoch: 4 6 loss: 175.731248437 169.547151591 6.18409684591\n",
      "-0.124479216448 0.0363476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 05:05:44.520177 epoch: 4 7 loss: 176.99227933 170.80863691 6.18364241989\n",
      "-0.124817441353 0.0365172\n",
      "2018-06-27 05:07:29.813262 epoch: 4 8 loss: 177.89648977 171.713000406 6.18348936392\n",
      "-0.125147885625 0.0366887\n",
      "2018-06-27 05:09:16.761509 epoch: 4 9 loss: 176.548415985 170.365891424 6.18252456124\n",
      "-0.125483475768 0.0368594\n",
      "2018-06-27 05:11:03.669486 epoch: 4 10 loss: 176.022821384 169.840224447 6.18259693661\n",
      "-0.125815062273 0.0370265\n",
      "2018-06-27 05:12:55.564394 epoch: 4 11 loss: 175.130158187 168.94822376 6.18193442687\n",
      "-0.12615965297 0.0371942\n",
      "2018-06-27 05:14:39.799544 epoch: 4 12 loss: 175.908955875 169.727504177 6.18145169779\n",
      "-0.126504752345 0.0373561\n",
      "2018-06-27 05:16:25.594126 epoch: 4 13 loss: 176.281766723 170.100770346 6.18099637715\n",
      "-0.12681795412 0.0375245\n",
      "2018-06-27 05:18:12.577286 epoch: 4 14 loss: 178.264684547 172.083734388 6.18095015941\n",
      "-0.127151657773 0.0376942\n",
      "2018-06-27 05:19:59.878962 epoch: 4 15 loss: 177.533237599 171.352884326 6.1803532727\n",
      "-0.127453881647 0.0378656\n",
      "2018-06-27 05:21:46.399942 epoch: 4 16 loss: 176.74724175 170.567739443 6.17950230763\n",
      "-0.127761763482 0.0380409\n",
      "2018-06-27 05:23:33.060891 epoch: 4 17 loss: 177.754809197 171.575446931 6.17936226562\n",
      "-0.128086101841 0.0382115\n",
      "2018-06-27 05:25:21.298271 epoch: 4 18 loss: 176.849581921 170.670760085 6.17882183559\n",
      "-0.128412978579 0.0383816\n",
      "2018-06-27 05:27:09.619264 epoch: 4 19 loss: 176.247444093 170.069025657 6.17841843605\n",
      "-0.128729792308 0.0385471\n",
      "2018-06-27 05:28:58.644483 epoch: 4 20 loss: 177.419606033 171.241513325 6.17809270794\n",
      "-0.129028380505 0.0387076\n",
      "2018-06-27 05:30:45.229820 epoch: 4 21 loss: 176.070722723 169.893143778 6.17757894421\n",
      "-0.129343662774 0.0388761\n",
      "2018-06-27 05:32:33.379887 epoch: 4 22 loss: 176.008214091 169.831412972 6.17680111873\n",
      "-0.129664622599 0.039032\n",
      "2018-06-27 05:34:19.970892 epoch: 4 23 loss: 176.718374591 170.542129751 6.17624483925\n",
      "-0.129958240493 0.0391952\n",
      "2018-06-27 05:36:06.442035 epoch: 4 24 loss: 176.389787256 170.213698717 6.17608853931\n",
      "-0.130257904 0.0393605\n",
      "2018-06-27 05:37:53.573806 epoch: 4 25 loss: 174.857756352 168.68253432 6.17522203199\n",
      "-0.130559200907 0.0395228\n",
      "2018-06-27 05:39:38.833959 epoch: 4 26 loss: 175.376327443 169.201453496 6.17487394791\n",
      "-0.130843470601 0.0396896\n",
      "2018-06-27 05:41:25.195375 epoch: 4 27 loss: 176.187224499 170.012709728 6.17451477104\n",
      "-0.131141928902 0.0398542\n",
      "2018-06-27 05:43:13.405749 epoch: 4 28 loss: 176.186009408 170.012030251 6.17397915646\n",
      "-0.131428824665 0.0400211\n",
      "2018-06-27 05:45:01.737805 epoch: 4 29 loss: 176.421787553 170.248141022 6.17364653082\n",
      "-0.131711415875 0.0401888\n",
      "2018-06-27 05:46:49.275648 epoch: 4 30 loss: 175.463771669 169.290689006 6.17308266236\n",
      "-0.13199981409 0.0403499\n",
      "2018-06-27 05:48:36.414713 epoch: 4 31 loss: 176.115323682 169.94258945 6.17273423129\n",
      "-0.132287957709 0.0405104\n",
      "2018-06-27 05:50:25.245867 epoch: 4 32 loss: 176.134822053 169.96231145 6.17251060233\n",
      "-0.132574393209 0.0406674\n",
      "2018-06-27 05:52:12.545789 epoch: 4 33 loss: 177.007110354 170.835149608 6.17196074652\n",
      "-0.132847473412 0.0408272\n",
      "2018-06-27 05:53:58.069707 epoch: 4 34 loss: 176.529309522 170.358183702 6.17112582018\n",
      "-0.133123371321 0.0409906\n",
      "2018-06-27 05:55:45.342869 epoch: 4 35 loss: 176.24111784 170.070041221 6.17107661985\n",
      "-0.133386419945 0.0411476\n",
      "2018-06-27 05:57:30.505631 epoch: 4 36 loss: 176.809902135 170.639301566 6.17060056873\n",
      "-0.133667826314 0.0413078\n",
      "2018-06-27 05:59:16.782165 epoch: 4 37 loss: 176.631130635 170.460866783 6.17026385277\n",
      "-0.133958061205 0.0414645\n",
      "2018-06-27 06:01:03.471773 epoch: 4 38 loss: 176.828822086 170.659053016 6.16976907076\n",
      "-0.134235649403 0.0416223\n",
      "2018-06-27 06:02:52.231019 epoch: 4 39 loss: 176.597081619 170.427338854 6.16974276515\n",
      "-0.134497007356 0.0417854\n",
      "2018-06-27 06:04:40.984419 epoch: 4 40 loss: 176.249114393 170.079518846 6.16959554687\n",
      "-0.134766411081 0.0419545\n",
      "2018-06-27 06:06:28.087170 epoch: 4 41 loss: 177.29133746 171.122767091 6.16857036958\n",
      "-0.135014138012 0.0421173\n",
      "2018-06-27 06:08:14.284435 epoch: 4 42 loss: nan 170.015857747 nan\n",
      "-0.135267524491 0.0422768\n",
      "2018-06-27 06:10:01.690520 epoch: 4 43 loss: 175.903283703 169.73561097 6.16767273323\n",
      "-0.135525673045 0.0424343\n",
      "2018-06-27 06:11:49.174688 epoch: 4 44 loss: 176.746982144 170.579651549 6.16733059525\n",
      "-0.135787874181 0.0425965\n",
      "2018-06-27 06:13:36.886383 epoch: 4 45 loss: 176.981634186 170.814553369 6.16708081665\n",
      "-0.136027633008 0.0427571\n",
      "2018-06-27 06:15:25.123458 epoch: 4 46 loss: 176.796194218 170.629414176 6.16678004238\n",
      "-0.136260792938 0.04292\n",
      "2018-06-27 06:17:10.323210 epoch: 4 47 loss: 175.282154587 169.116498325 6.16565626152\n",
      "-0.136506278769 0.0430839\n",
      "2018-06-27 06:18:58.008097 epoch: 4 48 loss: 176.016549848 169.85085113 6.16569871799\n",
      "-0.136736519458 0.043241\n",
      "2018-06-27 06:20:46.000179 epoch: 4 49 loss: 175.723548828 169.55824718 6.16530164806\n",
      "-0.136963562547 0.0434039\n",
      "2018-06-27 06:22:33.610426 epoch: 4 50 loss: 176.396965327 170.23212799 6.16483733714\n",
      "-0.137186605217 0.0435667\n",
      "2018-06-27 06:24:20.903199 epoch: 4 51 loss: 176.082513567 169.917905247 6.16460831933\n",
      "-0.137418676895 0.0437279\n",
      "2018-06-27 06:26:07.701436 epoch: 4 52 loss: 175.294441838 169.130659401 6.16378243715\n",
      "-0.137658940149 0.043886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # We must initialize all variables before we use them.\n",
    "    init.run()\n",
    "    for epoch in range(5):\n",
    "        for nn in range(53):\n",
    "            loadata = np.load('slice_data/0317data'+str(nn)+'.npz')\n",
    "            x_=loadata['InputX3D']\n",
    "            dmg_data = np.load('additional_fields/0317data'+str(nn)+'_additionalFields.npz')\n",
    "            x_dmg = dmg_data['values']\n",
    "            x_dmg[:,2] = abs(x_dmg[:,3]-2)\n",
    "            x_dmg = x_dmg[:,:3]\n",
    "            #seqs = load_obj('med2vec_input/seqs'+str(nn)+'.pkl')\n",
    "            #demos = load_obj('med2vec_input/demos'+str(nn)+'.pkl')\n",
    "            seqs, demos = [], []\n",
    "            for i in range(len(x_)):\n",
    "                if i > 0:\n",
    "                    seqs.append([-1])\n",
    "                    demos.append([0.,0.,0.])\n",
    "                for j in range(len(x_[i])):\n",
    "                    if np.sum(x_[i][j]) > 0:\n",
    "                        seqs.append(np.where(x_[i][j]==True)[0].tolist())\n",
    "                        demos.append(x_dmg[i].tolist())\n",
    "                    #else:\n",
    "                        #seqs.append([-1])\n",
    "                        #demos.append([0.,0.,0.])\n",
    "            n_batches = int(np.ceil(float(len(seqs)) / float(batchSize)))\n",
    "            total_loss,total_visit_loss = 0,0\n",
    "            for index in random.sample(range(n_batches), n_batches):\n",
    "                batchX = seqs[batchSize*index:batchSize*(index+1)]\n",
    "                batchD = demos[batchSize*index:batchSize*(index+1)]\n",
    "                batchX, mask_in, iVec, jVec = padMatrix(batchX)\n",
    "                feed_dict={x:batchX,d:batchD,mask:mask_in,iVector:iVec,jVector:jVec}\n",
    "                loss_val = session.run([optimizer, total_cost,visit_cost,tparams], feed_dict=feed_dict)\n",
    "                total_loss += loss_val[1]\n",
    "                total_visit_loss += loss_val[2]\n",
    "\n",
    "            avg_loss = total_loss / n_batches\n",
    "            avg_visit_loss = total_visit_loss / n_batches\n",
    "            print(datetime.now(),\"epoch:\",epoch,nn,\"loss:\",avg_loss,avg_visit_loss,avg_loss-avg_visit_loss)\n",
    "            print(np.mean(loss_val[-1]['W_emb']),np.mean(loss_val[-1]['b_emb']))\n",
    "        save_obj(loss_val[-1], 'med2vec_emb0626_adadelta_'+str(epoch)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save emb to pkl file\n",
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "#save_obj(loss_val[-1], 'med2vec_emb0625_5window_1e-5L2_adadelta1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_obj(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "dictionary = load_obj('dictionary.pkl')\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "trained_weights = load_obj('med2vec_emb0627_time_window_0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "emb_2d = TSNE(n_components=2).fit_transform(trained_weights['W_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = emb_2d[:,0]\n",
    "y = emb_2d[:,1]\n",
    "z = [reverse_dictionary[key] for key in range(553)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAHVCAYAAAAkfVjMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff002e0ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(x, y)\n",
    "\n",
    "#for i, txt in enumerate(z):\n",
    "#    ax.annotate(txt, (x[i],y[i]))\n",
    "\n",
    "#plt.savefig('med2vec0626_emb_tsne.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('med2vec_emb0627_time_window_tsne.txt','w') as out:\n",
    "    for i in range(553):\n",
    "        out.write(\"\\t\".join([reverse_dictionary[i],str(emb_2d[i,0]),str(emb_2d[i,1])])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38922136645494998"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "aaa = trained_weights['W_emb']\n",
    "cosine(emb_2d[dictionary['d127']],emb_2d[dictionary['p217']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 2018-06-27 14:39:40.327621\n"
     ]
    }
   ],
   "source": [
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "for nn in range(13,14):\n",
    "    print(nn,datetime.now())\n",
    "    loadata = np.load('slice_data/0317data'+str(nn)+'.npz')\n",
    "    x_=loadata['InputX3D']\n",
    "    dmg_data = np.load('additional_fields/0317data'+str(nn)+'_additionalFields.npz')\n",
    "    x_dmg = dmg_data['values']\n",
    "    x_dmg[:,2] = abs(x_dmg[:,3]-2)\n",
    "    x_dmg = x_dmg[:,:3]\n",
    "    seqs,demos = [],[]\n",
    "    for i in range(len(x_)):\n",
    "        if i > 0:\n",
    "            seqs.append([-1])\n",
    "            demos.append([0.,0.,0.])\n",
    "        for j in range(len(x_[i])):\n",
    "            if np.sum(x_[i][j]) > 0:\n",
    "                seqs.append(np.where(x_[i][j]==True)[0].tolist())\n",
    "                demos.append(x_dmg[i].tolist())\n",
    "    \n",
    "    save_obj(seqs,'med2vec_input/seqs'+str(nn)+'.pkl')\n",
    "    save_obj(demos,'med2vec_input/demos'+str(nn)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = 1\n",
    "loadata = np.load('slice_data/0317data'+str(nn)+'.npz')\n",
    "x_=loadata['InputX3D']\n",
    "dmg_data = np.load('additional_fields/0317data'+str(nn)+'_additionalFields.npz')\n",
    "x_dmg = dmg_data['values']\n",
    "x_dmg[:,2] = abs(x_dmg[:,3]-2)\n",
    "x_dmg = x_dmg[:,:3]\n",
    "#seqs = load_obj('med2vec_input/seqs'+str(nn)+'.pkl')\n",
    "#demos = load_obj('med2vec_input/demos'+str(nn)+'.pkl')\n",
    "seqs, demos, times = [], [], []\n",
    "tc = 0\n",
    "for i in range(len(x_)):\n",
    "    if i > 0:\n",
    "        seqs.append([-1])\n",
    "        demos.append([0.,0.,0.])\n",
    "    for j in range(len(x_[i])):\n",
    "        if np.sum(x_[i][j]) > 0:\n",
    "            seqs.append(np.where(x_[i][j]==True)[0].tolist())\n",
    "            demos.append(x_dmg[i].tolist())\n",
    "            times.append(tc)\n",
    "        tc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-27 17:40:20.752563 epoch: 0 0 loss: 233.431480276 227.114361342 6.31711893436\n",
      "5.90687e-05 0.00248667\n",
      "2018-06-27 17:41:44.564350 epoch: 0 1 loss: 221.390166518 215.073248107 6.31691841176\n",
      "0.00021934 0.0208227\n",
      "2018-06-27 17:43:08.016609 epoch: 0 2 loss: 207.377756993 201.061130432 6.31662656101\n",
      "0.000414918 0.0470061\n",
      "2018-06-27 17:44:31.729881 epoch: 0 3 loss: 192.913826264 186.597601033 6.31622523141\n",
      "0.000612021 0.0614483\n",
      "2018-06-27 17:45:54.686219 epoch: 0 4 loss: 186.472488435 180.156779496 6.31570893956\n",
      "0.000774014 0.0666746\n",
      "2018-06-27 17:47:24.826472 epoch: 0 5 loss: 181.729097132 175.41390366 6.31519347206\n",
      "0.000879209 0.069424\n",
      "2018-06-27 17:48:56.389614 epoch: 0 6 loss: 179.590410013 173.275676514 6.31473349933\n",
      "0.00093529 0.0712212\n",
      "2018-06-27 17:50:27.411700 epoch: 0 7 loss: 180.049035572 173.734627405 6.31440816698\n",
      "0.000949356 0.0723323\n",
      "2018-06-27 17:51:50.818051 epoch: 0 8 loss: 180.49378733 174.179614157 6.31417317312\n",
      "0.000940036 0.0730038\n",
      "2018-06-27 17:53:20.515453 epoch: 0 9 loss: 178.90089919 172.586931039 6.31396815063\n",
      "0.000916873 0.0734133\n",
      "2018-06-27 17:54:49.397653 epoch: 0 10 loss: 178.247323707 171.933483307 6.31384039966\n",
      "0.00088226 0.0736961\n",
      "2018-06-27 17:56:18.081775 epoch: 0 11 loss: 177.40624111 171.09253254 6.31370857039\n",
      "0.000841642 0.0739101\n",
      "2018-06-27 17:57:39.533334 epoch: 0 12 loss: 178.091486381 171.777862086 6.31362429499\n",
      "0.000794647 0.0739835\n",
      "2018-06-27 17:59:05.731576 epoch: 0 13 loss: 178.456157659 172.142611029 6.31354663064\n",
      "0.000746361 0.0740344\n",
      "2018-06-27 18:00:27.357452 epoch: 0 14 loss: 180.216312374 173.902809655 6.31350271912\n",
      "0.000693072 0.0739899\n",
      "2018-06-27 18:01:56.479935 epoch: 0 15 loss: 179.701752413 173.38828608 6.31346633307\n",
      "0.00064046 0.0739356\n",
      "2018-06-27 18:03:23.519820 epoch: 0 16 loss: 179.099261492 172.785860265 6.3134012276\n",
      "0.000587752 0.0738886\n",
      "2018-06-27 18:04:50.829803 epoch: 0 17 loss: 180.000143944 173.686770573 6.3133733709\n",
      "0.000533487 0.0737906\n",
      "2018-06-27 18:06:19.128065 epoch: 0 18 loss: 179.05371559 172.740400844 6.31331474578\n",
      "0.000481918 0.0737158\n",
      "2018-06-27 18:07:48.128186 epoch: 0 19 loss: 178.595289361 172.282006293 6.31328306751\n",
      "0.000428061 0.0736136\n",
      "2018-06-27 18:09:16.028643 epoch: 0 20 loss: 179.595293125 173.282060069 6.31323305678\n",
      "0.000376422 0.0735106\n",
      "2018-06-27 18:10:44.915854 epoch: 0 21 loss: 178.455828853 172.142642347 6.31318650585\n",
      "0.000323788 0.0734127\n",
      "2018-06-27 18:12:12.145348 epoch: 0 22 loss: 178.429312741 172.116192565 6.31312017605\n",
      "0.000272646 0.0733185\n",
      "2018-06-27 18:13:41.658015 epoch: 0 23 loss: 179.105816319 172.792717712 6.31309860648\n",
      "0.000220912 0.0732016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # We must initialize all variables before we use them.\n",
    "    init.run()\n",
    "    for epoch in range(5):\n",
    "        for nn in range(53):\n",
    "            loadata = np.load('slice_data/0317data'+str(nn)+'.npz')\n",
    "            x_=loadata['InputX3D']\n",
    "            dmg_data = np.load('additional_fields/0317data'+str(nn)+'_additionalFields.npz')\n",
    "            x_dmg = dmg_data['values']\n",
    "            x_dmg[:,2] = abs(x_dmg[:,3]-2)\n",
    "            x_dmg = x_dmg[:,:3]\n",
    "            #seqs = load_obj('med2vec_input/seqs'+str(nn)+'.pkl')\n",
    "            #demos = load_obj('med2vec_input/demos'+str(nn)+'.pkl')\n",
    "            seqs, demos = [], []\n",
    "            for i in range(len(x_)):\n",
    "                if i > 0:\n",
    "                    seqs.append([-1])\n",
    "                    demos.append([0.,0.,0.])\n",
    "                for j in range(len(x_[i])):\n",
    "                    if np.sum(x_[i][j]) > 0:\n",
    "                        seqs.append(np.where(x_[i][j]==True)[0].tolist())\n",
    "                        demos.append(x_dmg[i].tolist())\n",
    "                    #else:\n",
    "                        #seqs.append([-1])\n",
    "                        #demos.append([0.,0.,0.])\n",
    "            n_batches = int(np.ceil(float(len(seqs)) / float(batchSize)))\n",
    "            total_loss,total_visit_loss = 0,0\n",
    "            for index in random.sample(range(n_batches), n_batches):\n",
    "                batchX = seqs[batchSize*index:batchSize*(index+1)]\n",
    "                batchD = demos[batchSize*index:batchSize*(index+1)]\n",
    "                batchX, mask_in, iVec, jVec = padMatrix(batchX)\n",
    "                feed_dict={x:batchX,d:batchD,mask:mask_in,iVector:iVec,jVector:jVec}\n",
    "                loss_val = session.run([optimizer, total_cost,visit_cost,tparams], feed_dict=feed_dict)\n",
    "                total_loss += loss_val[1]\n",
    "                total_visit_loss += loss_val[2]\n",
    "\n",
    "            avg_loss = total_loss / n_batches\n",
    "            avg_visit_loss = total_visit_loss / n_batches\n",
    "            print(datetime.now(),\"epoch:\",epoch,nn,\"loss:\",avg_loss,avg_visit_loss,avg_loss-avg_visit_loss)\n",
    "            print(np.mean(loss_val[-1]['W_emb']),np.mean(loss_val[-1]['b_emb']))\n",
    "        #save_obj(loss_val[-1], 'med2vec_emb0626_adadelta_'+str(epoch)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 200)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_weights['W_hidden'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
